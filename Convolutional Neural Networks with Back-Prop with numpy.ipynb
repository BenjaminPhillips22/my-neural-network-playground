{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import input_data\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting .\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting .\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting .\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting .\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(train_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_number(image_array):\n",
    "    \"\"\"\n",
    "    image_array is the array that represents a\n",
    "    single mnist image. it has shape (784, )\n",
    "    and needs to be reshaped.\n",
    "    \"\"\"\n",
    "    X = image_array\n",
    "    X = X.reshape([28, 28]);\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.gray()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAACPCAYAAAARM4LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABP1JREFUeJzt3U0orG0cx/F7Tk+EjVKUl7x0ys5KKSdOElnZWNmwwolQ\nyFYsKSmdZMWGZKFQShZe8pYoWVlYiJQ6p0hSJvFsnkf+V8c0zG9uzsz3s5pf7pm5Ov3ONZf7vucS\neHp68oBIffnoASA2UCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRI/OPnmwUCAU6j/2Wenp4C4RzHjAQJ\nigQJigQJigQJigQJigQJigQJigQJigQJigQJigQJX6+1xaqEhASTl5eXTd7c3DQ5LS3N5JaWlpDH\nf//+PdIhRh0zEiQoEiQoEiRYIwl0d3ebXF5ebnJZWVnI57vfdr65udEMzEfMSJCgSJDgo+0TODs7\nM/nHjx8fNJL3Y0aCBEWCBEWCBGskgfT09Dcdf39/b/Lw8LDJFxcXEY/Jb8xIkKBIkKBIkGCN9E5t\nbW3Pj1tbW0MeGwwGTe7t7TX558+fuoF9EGYkSFAkSFAkSAT83LD9b97WJjs72+TDw8Pnx6mpqeZn\nj4+PJnd2dpo8NjYmHl30sK0NfEWRIEGRIMEa6RU5OTkmz8/Pm1xUVPTqcw8ODkwuKSnRDcxnrJHg\nK4oECYoECa61vaKpqcnkUGuio6Mjk2tqaqIyps+MGQkSFAkSFAkSrJH+494j5OZQBgYGTL66ujI5\nJSXF5J6eHpObm5tNPj8/N3lqasrkmZkZk3/9+hX2WKOFGQkSFAkSFAkScXutrbS01OS1tTWTv3wJ\n/X+ssbHx+fH09LT5WV9fn8ldXV0mJycnhzvMP3Lfr6GhIaLXC4VrbfAVRYIERYJE3KyRMjMzTV5f\nXze5oKDA5IeHB5P39vZMrq2tfX7snteprq422b2HW62wsNDkk5MT2WuzRoKvKBIk4uYSifvRlZ+f\nb7L7ET83N2dyfX29yQsLC8+PKysrzc/cjzL3tU9PT00eGRkJOdaOjg4vlKqqKpOVH23hYkaCBEWC\nBEWCRNyskdrb2990/NLSkskvf933PM+rqKh49bnu1n7utjfuXz9ybxsZHBwMe5ye53mXl5dvOj4a\nmJEgQZEgQZEgEbNrpMTERJPdrWdcL7ep8TzP+/37t8nuZZCkpKRXX2t0dNTkyclJk3Nzc01210Qv\ntxX8k52dHZNXVlZCHu8HZiRIUCRIUCRIxOwayd2Wxr0e5lpdXTW5uLjYZPcrRS9tb2+bvLi4aLL7\nFe7x8XGTs7KyQo7Ntbu7a/Lt7e2bnh8NzEiQoEiQoEiQiNlbbb9+/Wry8fGxX2/tBQL27tRI/43d\nrx+51+6iuUbiVlv4iiJBgiJBImbPI3379u2jhxC26+trkycmJkzu7+83+TOcN3IxI0GCIkGCIkEi\nZs8jZWRkmLy1tWVyXl5e1N7bPY90d3dnsntv0+zsrMmf4f6i/3EeCb6iSJCgSJCI2TWSy936xd3S\nuK6u7t2vvb+/b/LGxobJQ0NDJn+G7YzDxRoJvqJIkKBIkIibNZLLPY/kbo/s/nl2909pvVxjufsE\nBIPByAf4SbBGgq8oEiQoEiTido2E8LBGgq8oEiQoEiQoEiQoEiQoEiQoEiQoEiQoEiQoEiQoEiQo\nEiQoEiQoEiQoEiQoEiQoEiQoEiR8vdUWsYsZCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRIU\nCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRIUCRL/Ai6RPbgVKYBZAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15d1dca12b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_number(mnist.train.images[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAABbCAYAAAAC7OPyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15d1d9736d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "for i in range(1, 10):\n",
    "    ax = fig.add_subplot(1, 10, i)\n",
    "    X = mnist.train.images[i]\n",
    "    X = X.reshape([28, 28])\n",
    "    ax.axis('off')\n",
    "    ax.imshow(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 6, 1, 8, 1, 0, 9, 8], dtype=uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9960785\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(mnist.train.images[0]))\n",
    "print(np.min(mnist.train.images[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_numbers(labels):\n",
    "    \n",
    "    if isinstance(labels, np.uint8):\n",
    "        num_labels = 1\n",
    "        labels = [labels]\n",
    "    else:\n",
    "        num_labels = labels.shape[0]\n",
    "        \n",
    "    one_hots = np.zeros(shape=(num_labels, 10))\n",
    "    \n",
    "    for i in range(num_labels):\n",
    "        one_hots[i, labels[i]]=1\n",
    "\n",
    "    return one_hots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 4 6 0 1 2 3 4 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = mnist.train.labels[1100:1109]\n",
    "print(abc)\n",
    "one_hot_encode_numbers(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[0:3][0].reshape(28, 28).shape\n",
    "# [i for i in 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 28, 28)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reshape_images(images):\n",
    "    \"\"\"\n",
    "    images is a np array of n images\n",
    "    each with size (784,) that need\n",
    "    to be reshaped\n",
    "    \"\"\"\n",
    "    # if it doesn't have a second dimension, it's a single image\n",
    "    try:\n",
    "        images.shape[1]\n",
    "    except:\n",
    "        return images.reshape(28, 28)\n",
    "    \n",
    "    reshaped = np.stack([images[i].reshape(28, 28) for i in range(images.shape[0])])\n",
    "\n",
    "    return reshaped\n",
    "    \n",
    "reshape_images(mnist.train.images[0:3]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 55000\n",
      "number of validation examples = 5000\n",
      "number of test examples = 10000\n",
      "Input images are of size = (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training examples = \" + str(mnist.train.images.shape[0]))\n",
    "print(\"number of validation examples = \" + str(mnist.validation.images.shape[0]))\n",
    "print(\"number of test examples = \" + str(mnist.test.images.shape[0]))\n",
    "print(\"Input images are of size = \" + str(mnist.train.images[0].reshape(28,28).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00277795 -0.00047347 -0.00941613]\n",
      " [ 0.00366754  0.00153648 -0.00412454]\n",
      " [-0.0061554  -0.00078805  0.00019837]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00277795, 0.        , 0.        ],\n",
       "       [0.00366754, 0.00153648, 0.        ],\n",
       "       [0.        , 0.        , 0.00019837]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = np.random.normal(scale=0.01, size=(3,3))\n",
    "print(aaa)\n",
    "def relu(num):\n",
    "    return np.max([num,0])\n",
    "relu_layer = np.vectorize(relu)\n",
    "\n",
    "#test\n",
    "relu_layer(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02285293 -0.00717831  0.00523548]\n",
      " [ 0.01581124  0.00822494  0.00711687]\n",
      " [ 0.0024365   0.01192195 -0.00652337]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01581124276079739"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = np.random.normal(scale=0.01, size=(3,3))\n",
    "print(aaa)\n",
    "\n",
    "def max_pool(grid):\n",
    "    return np.max(grid)\n",
    "\n",
    "# test\n",
    "max_pool(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class conv_net(object):\n",
    "    \"\"\"\n",
    "    class for a convolutional neural network.\n",
    "    \n",
    "    layers:\n",
    "    input layer \n",
    "                - the image, size (28, 28)\n",
    "    conv layer \n",
    "                - weights W1 \n",
    "                - padding 'VALID', stride 2\n",
    "                - size(4, 4)\n",
    "                - output size (16, 16)\n",
    "    relu layer \n",
    "                - output size (16, 16)\n",
    "    max_pool\n",
    "                - padding 'VALID', stride 2\n",
    "                - size (4, 4)\n",
    "                - output will be (8, 8)\n",
    "    conv layer \n",
    "                - weights W2 \n",
    "                - padding 'VALID', stride 2\n",
    "                - size(2, 2)\n",
    "                - output size (4, 4)\n",
    "    relu layer\n",
    "                - output size (4, 4)\n",
    "    max_pool\n",
    "                - padding 'VALID', stride 2\n",
    "                - size (2, 2)\n",
    "                - output size (2, 2)\n",
    "    reshape layer\n",
    "                - reshape to size (4,)\n",
    "    fully connected layer\n",
    "                - weights W3\n",
    "                - size (40)\n",
    "                - output size (10,)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, seed):\n",
    "        self.seed = seed\n",
    "    \n",
    "    def set_seed(self):\n",
    "        np.random.seed(self.seed)\n",
    "    \n",
    "    def initialise_weights(self):\n",
    "        self.W1 = np.random.normal(scale=0.01, size=(4,4))\n",
    "        self.W2 = np.random.normal(scale=0.01, size=(2,2))\n",
    "        self.W3 = np.random.normal(scale=0.01, size=(40,))\n",
    "    \n",
    "    def forward_pass(image):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0270685 ,  0.00628133,  0.00907969],\n",
       "       [ 0.00503826,  0.00651118, -0.00319318],\n",
       "       [-0.00848077,  0.00605965, -0.02018168]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq = conv_net(101)\n",
    "qq.set_seed()\n",
    "qq.initialise_weights()\n",
    "qq.W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create network\n",
    "np.random.seed(10)\n",
    "# structure will be\n",
    "#\n",
    "# CONV2D: stride of 1, padding 'SAME' (padding of 1 around)\n",
    "# so output will be (28, 28)\n",
    "Z1 = np.random.normal(scale=0.01, size=(3,3))\n",
    "# RELU \n",
    "# applies max(num, 0) to each element, output (28, 28)\n",
    "# apply to Z1\n",
    "A1 = relu_layer(Z1)\n",
    "# MAXPOOL: window 4x4, sride 4, padding 'SAME', (2 around)\n",
    "# out_height = ceil(float(in_height) / float(strides[1]))\n",
    "# out_width = ceil(float(in_width) / float(strides[2]))\n",
    "# so output will be (7, 7)\n",
    "P1 = max_pool(A1)\n",
    "# CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "# grid of 3 by 3, padding of 1 around, output will be (7, 7)\n",
    "Z2 = np.random.normal(scale=0.01, size=(3,3))\n",
    "# RELU, again output will be (7, 7)\n",
    "A2 = relu_layer(Z2)\n",
    "# MAXPOOL: window 3x3, stride 2, padding 'SAME' (padding of 1)\n",
    "# output size (4, 4)\n",
    "P2 = None\n",
    "# FLATTEN\n",
    "# reshape into 1 dimension\n",
    "# output 16\n",
    "P2 = None # np.random.normal(scale=0.01, size=(16,))\n",
    "# FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "# 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "Z3 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
